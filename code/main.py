import streamlit as st
from dotenv import load_dotenv
from rag_pipeline.vector_store import load_data
from rag_pipeline.llm import answer_question
from processing.data_processing import load_chunks
from rag_pipeline.hybrid_rag import HybridRAG

load_dotenv()

@st.cache_resource
def initialize_rag_system():
    """RAG áƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒ›áƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ"""
    chunks = load_chunks()
    collection = load_data(chunks)

    return HybridRAG(collection, chunks)

def main():
    """
    áƒ”áƒ¡ áƒ¤áƒ£áƒœáƒ¥áƒªáƒ˜áƒ áƒ¬áƒáƒ áƒ›áƒáƒáƒ“áƒ’áƒ”áƒœáƒ¡ Streamlit áƒáƒáƒšáƒ˜áƒ™áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ«áƒ˜áƒ áƒ˜áƒ—áƒáƒ“ áƒšáƒáƒ’áƒ˜áƒ™áƒáƒ¡, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒ¥áƒ›áƒœáƒ˜áƒ¡ áƒ˜áƒœáƒ¢áƒ”áƒ áƒáƒ¥áƒ¢áƒ˜áƒ£áƒš AI áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ¡ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¡ áƒ¡áƒáƒ›áƒáƒ¥áƒáƒšáƒáƒ¥áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.
    """

    st.set_page_config(page_title="AI áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜", page_icon="ğŸ¤–", layout="centered")
    st.title("áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¡ áƒ¡áƒáƒ›áƒáƒ¥áƒáƒšáƒáƒ¥áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜áƒ¡ AI RAG áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜")

    welcome = """
    ğŸ‘‹ áƒ’áƒáƒ›áƒáƒ áƒ¯áƒáƒ‘áƒ!\n
    áƒ›áƒ” áƒ•áƒáƒ  **AI áƒ˜áƒ£áƒ áƒ˜áƒ“áƒ˜áƒ£áƒšáƒ˜ áƒáƒ¡áƒ˜áƒ¡áƒ¢áƒ”áƒœáƒ¢áƒ˜**, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒ¡áƒáƒ”áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ **áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¡ áƒ¡áƒáƒ›áƒáƒ¥áƒáƒšáƒáƒ¥áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ¨áƒ˜**.\n
    áƒ¨áƒ”áƒ’áƒ˜áƒ«áƒšáƒ˜áƒáƒ— áƒ›áƒáƒ›áƒ¬áƒ”áƒ áƒáƒ— áƒœáƒ”áƒ‘áƒ˜áƒ¡áƒ›áƒ˜áƒ”áƒ áƒ˜ áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ“áƒ áƒ›áƒ” áƒ›áƒáƒ’áƒáƒ¬áƒ•áƒ“áƒ˜áƒ— áƒ–áƒ£áƒ¡áƒ¢ áƒ“áƒ áƒ¡áƒ¢áƒ áƒ£áƒ¥áƒ¢áƒ£áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒš áƒáƒáƒ¡áƒ£áƒ®áƒ¡ **áƒ›áƒ®áƒáƒšáƒáƒ“ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜áƒ¡ áƒ¢áƒ”áƒ¥áƒ¡áƒ¢áƒ–áƒ” áƒ“áƒáƒ§áƒ áƒ“áƒœáƒáƒ‘áƒ˜áƒ—.**    
    """

    # Initialize the entire RAG system and cache it
    rag = initialize_rag_system()

    with st.chat_message("ai"):
        st.write(welcome)



    # Initialize chat history
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Display previous messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Accept user input
    if prompt := st.chat_input("áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ¨áƒ”áƒ™áƒ˜áƒ—áƒ®áƒ•áƒ áƒ¡áƒáƒ¥áƒáƒ áƒ—áƒ•áƒ”áƒšáƒáƒ¡ áƒ¡áƒáƒ›áƒáƒ¥áƒáƒšáƒáƒ¥áƒ áƒ™áƒáƒ“áƒ”áƒ¥áƒ¡áƒ˜áƒ¡ áƒ¨áƒ”áƒ¡áƒáƒ®áƒ”áƒ‘"):
        # Store user input
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Stream response
        results = rag.retrieve(prompt)

        context = "\n\n".join(results)

        
        with st.status("áƒ•áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘ áƒáƒáƒ¡áƒ£áƒ®áƒ¡!...", expanded=True) as status:
            with st.chat_message("ai"):
                response = answer_question(prompt, context)
                # print(response)
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            status.update(
                label="áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ!", state="complete", expanded=True
                )
    

if __name__ == "__main__":
    main()